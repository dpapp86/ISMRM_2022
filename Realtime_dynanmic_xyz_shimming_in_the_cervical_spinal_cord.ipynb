{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dpapp86/ISMRM_2022/blob/main/Realtime_dynanmic_xyz_shimming_in_the_cervical_spinal_cord.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-dbglbj294O"
      },
      "source": [
        "This is an interactive notebook for the following ISMRM digital poster:\n",
        "\n",
        " **\"Realtime Dynamic XYZ-shimming in the cervical spinal cord\"**\n",
        "Daniel Papp, Alexandre D'Astous, Jullien Cohen-Adad, Eva Alonso-Ortiz\n",
        "\n",
        "Program number 2353\n",
        "\n",
        "In brief, within this poster, we demonstrate that for best outcomes, respiration-induced B0 distortions need to be compensated for using realtime (varying with respiration), dynamic (slicewise) shimming gradients played out both through-plane (z) and in-plane (x-y) as well. Please refer to the poster for more information.\n",
        "\n",
        "This notebook demonstrates our processing pipeline, including necessary sanity checks, and provides examples of data visualisation. \n",
        "\n",
        "An effort has been made to make the notebook self-explanatory and well commented. However, any comments/issues should be directed at Daniel Papp (daniel.papp@polymtl.ca)\n",
        "\n",
        "This notebook will do the following:\n",
        "\n",
        "\n",
        "1.   Install all the necessary toolboxes, libraries, and finally download the data from OSF\n",
        "2.   Using the Spinal Cord Toolbox, segment the spinal cord from the T1w scan and apply this segmentation to all MGRE scans, following a coregistration step\n",
        "3. Extract the relevant data (signal intensity within the spinal cord for each slice, TE, and shimming condition)\n",
        "4. Generate plots of the standard deviation and mean of this signal across slices for each TE and shim condition (see poster)\n",
        "5. Generate violin plots for better visualisation\n",
        "\n",
        "Enjoy!\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup: importing toolboxes, libraries, and data"
      ],
      "metadata": {
        "id": "ebfj5rQeXCR-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sw8gt1Iu6W0Y"
      },
      "outputs": [],
      "source": [
        "# IMPORTING LIBRARIES AND INSTALLING NECESSARY TOOLS\n",
        "# First, lets make sure we are in the right directory for all the path definitions to work (/content/)\n",
        "import os\n",
        "currpath=os.getcwd()\n",
        "if currpath!='/content':\n",
        "  print(\"********** Not in the correct directory for the rest of the code, changing directories **********\")\n",
        "  os.chdir('/content/')\n",
        "else:\n",
        "  print(\"********** In the correct directory, proceeding **********\")\n",
        "\n",
        "#Now we can import all the necessary libraries\n",
        "\n",
        "\n",
        "\n",
        "# Path handling, file operations, etc\n",
        "import os\n",
        "from os.path import join\n",
        "import glob\n",
        "import zipfile\n",
        "import shutil\n",
        "import logging\n",
        "import subprocess\n",
        "import fnmatch\n",
        "import pathlib\n",
        "import time\n",
        "\n",
        "# Pydicom needs to be installed if we want to import it\n",
        "!pip install pydicom > /dev/null\n",
        "import pydicom\n",
        "print(\"********** Pydicom installed **********\")\n",
        "# Data handling, visualisation, etc\n",
        "\n",
        "import json\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import nibabel as nib\n",
        "import pandas as pd\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "# DCM2NIIX is necessary for DCM-to-NIFTI conversion after the DCM data has been checked for table position issues\n",
        "os.chdir('/content/')\n",
        "!git clone https://github.com/rordenlab/dcm2niix.git > /dev/null\n",
        "os.chdir('/content/dcm2niix')\n",
        "if os.path.isdir('/content/dcm2niix/build/'): #Here, we remove old, trailing installs (from an interrupter runtime, let's say) so we can start with a clean slate\n",
        "  shutil.rmtree('/content/dcm2niix/build/')\n",
        "os.mkdir('/content/dcm2niix/build/')\n",
        "os.chdir('/content/dcm2niix/build/')\n",
        "!cmake ..\n",
        "!make install > /dev/null #Suppressing outputs to keep the output readibly small. Errors are NOT supressed\n",
        "\n",
        "os.environ['PATH'] += ':/content/dcm2niix/build/bin/'\n",
        "print(\"********** DCM2NIIX installed **********\")\n",
        "\n",
        "######### Spinal cord toolbox installation\n",
        "os.chdir('/content/')\n",
        "!git clone --depth 1 --branch 5.3.0 https://github.com/spinalcordtoolbox/spinalcordtoolbox > /dev/null\n",
        "% cd spinalcordtoolbox/\n",
        "!yes | ./install_sct > /dev/null\n",
        "print(\"********** Spinal Cord Toolbox installed **********\")\n",
        "\n",
        "######### Spinal cord toolbox environment setup\n",
        "os.environ['PATH'] += ':/content/spinalcordtoolbox/bin'\n",
        "os.environ['SCT_DIR'] = '/content/spinalcordtoolbox'\n",
        "print(\"********** Spinal Cord Toolbox path set **********\")\n",
        "\n",
        "# We host our data on OSF\n",
        "# To handle it, we need the OSF client, installed here\n",
        "os.chdir('/content/')\n",
        "! git clone https://github.com/osfclient/osfclient > /dev/null\n",
        "\n",
        "% cd osfclient/ \n",
        "\n",
        "! pip install osfclient > /dev/null\n",
        "print('********** OSF client installed **********')\n",
        "## Here, we download the dataset shown in the ISMRM abstract\n",
        "os.chdir('/content/osfclient/')\n",
        "! osf -p fy3h4 fetch /ISMRM/Subjects.zip /content/osfclient/Subjects.zip\n",
        "print(\"********** ISMRM data suscesfully downloaded **********\")\n",
        "zipped_subject='/content/osfclient/Subjects.zip'\n",
        "with zipfile.ZipFile(zipped_subject,\"r\") as zip_ref:\n",
        "  zip_ref.extractall('/content/')\n",
        "# clearing up annoying _MACOSX directory\n",
        "shutil.rmtree('/content/__MACOSX')\n",
        "print(\"********** Unzipping done **********\")    \n",
        "\n",
        "# Helper function wrapping subprocess\n",
        "def run_subprocess(cmd):\n",
        "    \"\"\"Wrapper for ``subprocess.run()`` that enables to input ``cmd`` as a full string (easier for debugging).\n",
        "    Args:\n",
        "        cmd (string): full command to be run on the command line\n",
        "    \"\"\"\n",
        "    # logging.debug(f'{cmd}')\n",
        "    try:\n",
        "        subprocess.run(\n",
        "            cmd.split(' '),\n",
        "            text=True,\n",
        "            check=True\n",
        "            # env=env\n",
        "        )\n",
        "    except subprocess.CalledProcessError as err:\n",
        "        msg = \"Return code: \", err.returncode, \"\\nOutput: \", err.stderr\n",
        "        raise Exception(msg)\n",
        "\n",
        "\n",
        "\n",
        "print('********** All necessary libraries imported, all necessary toolboxes installed! **********')\n",
        "print('********** We can proceeed **********')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sanity check: are all shim settings the same?"
      ],
      "metadata": {
        "id": "U-KfqM5tdZuq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pT5oLldNwQIr"
      },
      "outputs": [],
      "source": [
        "# Checking that the shim values are the same for MGRE and B0-map scans\n",
        "\n",
        "# For our experiment, it is crucial that the first and second order shim values do not change between the B0 map\n",
        "# and the MGRE scans. If the shim settings were not the same, then the B0 field would be different, thus the \n",
        "# compensation gradients, derived from the B0 field map scan, would be incorrect.\n",
        "# To check for this, we compare the \"shimsetting\" tag in the JSON \n",
        "# files that are crated during DCM-to-NIFTI conversion (using DCM2NIIX)\n",
        "# We only check for the first number (corresponding to the first-order x-shim)\n",
        "# as any change in the shim values would change that as well\n",
        "\n",
        "# Start of loop\n",
        "Subjectdirs=sorted(glob.glob('/content/Subjects/'+'/*')) #Let's see how many subjects we have (for the pruposes of this demo, 1)\n",
        "# Note: This is a very MATLAB-inspired way of vectorisation\n",
        "for subject in range(len(Subjectdirs)): # First, we loop over every subject\n",
        "  runlist = glob.glob(Subjectdirs[subject]+ '/nifti/*') #We determine if more than one set of acquisitions (runs) was carried out for this subject\n",
        "  for runs in range(len(runlist)) : #And we loop over them\n",
        "    if fnmatch.fnmatch(runlist[runs], '*Lowres_run1*') : #Identifying the first low-resolution MGRE run\n",
        "      lowres_run1_fieldmaps = sorted(glob.glob(runlist[runs]+'/*field_mapping*.json')) #And grabbing the appropriate field map JSON files\n",
        "      # NOTE: because we have both phase and magnitude images in the converted field map, there is more than one JSON file\n",
        "      # Thus we need to handle this by pre-allocating a vector for the corresponding values\n",
        "      # The \"shimsetting\" field for the magnitude and phase image should be the same, but this was, we can catch an error\n",
        "      # For exampple if two field maps (two separate scans) were supplied with the data\n",
        "\n",
        "      lowres_run1_fieldmap_shim0=[None]*len(lowres_run1_fieldmaps) #Preallocation of the vector\n",
        "      for lr_1_fm in range(len(lowres_run1_fieldmaps)):\n",
        "          shimfilename = pathlib.Path(lowres_run1_fieldmaps[lr_1_fm])\n",
        "          with open (shimfilename,'r') as shim:\n",
        "            lowres_run1_fieldmap_shim0[lr_1_fm]=json.load(shim)[\"ShimSetting\"][0] #We fetch the x-shim value\n",
        "\n",
        "      # Now, we fetch the shim values for all MGRE scans. Since they all have SHIM in their name, and all of their\n",
        "      # shim values have to match, we do not need to handle them separately. It is worth having a second check here\n",
        "      # to make sure we have five, and only five, MGRE scans. If we don't, something is wrong, and we should exit\n",
        "      lowres_r1_GRE_SHIM = sorted(glob.glob(runlist[runs]+'/*SHIM*.json'))\n",
        "      if not len(lowres_r1_GRE_SHIM) == 5 :\n",
        "        print('********** More or less than five MGRE scans in this directory:', runlist[runs], '**********')\n",
        "        print(\"********** Exiting! **********\")\n",
        "        break\n",
        "      lowres_r1_GRE_SHIM0=[None]*len(lowres_r1_GRE_SHIM)\n",
        "      for lr_r1_SHIM in range(len(lowres_r1_GRE_SHIM)):\n",
        "          shimfilename = pathlib.Path(lowres_r1_GRE_SHIM[lr_r1_SHIM])\n",
        "          with open (shimfilename,'r') as shim:\n",
        "            lowres_r1_GRE_SHIM0[lr_r1_SHIM]=json.load(shim)[\"ShimSetting\"][0] #Again, fetching only the x component, not all 8\n",
        "            \n",
        "      # Comparing the first order x-shim of the MGRE scan to the first order x-shim of the field map\n",
        "      # If they don't match, we just remove this directory form further processing alltogether\n",
        "      if len(lowres_r1_GRE_SHIM0) > 0 :\n",
        "        lowres_r1_shim_match = all(elem == lowres_run1_fieldmap_shim0[0] for elem in lowres_r1_GRE_SHIM0)\n",
        "      if not lowres_r1_shim_match:\n",
        "        print('********** Shim values check failed by', runlist[runs], '**********')\n",
        "        shutil.rmtree(runlist[runs])  \n",
        "\n",
        "    if fnmatch.fnmatch(runlist[runs], '*Lowres_run2*') : #Identifying the second low-resolution MGRE run, should it exist\n",
        "      lowres_run2_fieldmaps = sorted(glob.glob(runlist[runs]+'/*field_mapping*.json')) #And grabbing the appropriate field map JSON files\n",
        "      # NOTE: because we have both phase and magnitude images in the converted field map, there is more than one JSON file\n",
        "      # Thus we need to handle this by pre-allocating a vector for the corresponding values\n",
        "      # The \"shimsetting\" field for the magnitude and phase image should be the same, but this was, we can catch an error\n",
        "      # For exampple if two field maps (two separate scans) were supplied with the data\n",
        "\n",
        "      lowres_run2_fieldmap_shim0=[None]*len(lowres_run2_fieldmaps) #Preallocation of the vector\n",
        "      for lr_2_fm in range(len(lowres_run2_fieldmaps)):\n",
        "          shimfilename = pathlib.Path(lowres_run2_fieldmaps[lr_2_fm])\n",
        "          with open (shimfilename,'r') as shim:\n",
        "            lowres_run2_fieldmap_shim0[lr_2_fm]=json.load(shim)[\"ShimSetting\"][0] #We fetch the x-shim value\n",
        "\n",
        "      # Now, we fetch the shim values for all MGRE scans. Since they all have SHIM in their name, and all of their\n",
        "      # shim values have to match, we do not need to handle them separately. It is worth having a second check here\n",
        "      # to make sure we have five, and only five, MGRE scans. If we don't, something is wrong, and we should exit\n",
        "      lowres_r2_GRE_SHIM = sorted(glob.glob(runlist[runs]+'/*SHIM*.json'))\n",
        "      if not len(lowres_r2_GRE_SHIM) == 5:\n",
        "        print('********** More or less than five MGRE scans in this directory:', runlist[runs], '**********')\n",
        "        print(\"********** Exiting! **********\")\n",
        "        break\n",
        "      lowres_r2_GRE_SHIM0=[None]*len(lowres_r2_GRE_SHIM)\n",
        "      for lr_r2_SHIM in range(len(lowres_r2_GRE_SHIM)):\n",
        "          shimfilename = pathlib.Path(lowres_r2_GRE_SHIM[lr_r2_SHIM])\n",
        "          with open (shimfilename,'r') as shim:\n",
        "            lowres_r2_GRE_SHIM0[lr_r2_SHIM]=json.load(shim)[\"ShimSetting\"][0] #Again, fetching only the x component, not all 8\n",
        "            \n",
        "      # Comparing the first order x-shim of the MGRE scan to the first order x-shim of the field map\n",
        "      # If they don't match, we just remove this directory form further processing alltogether\n",
        "      if len(lowres_r2_GRE_SHIM0) > 0 :\n",
        "        lowres_r2_shim_match = all(elem == lowres_run2_fieldmap_shim0[0] for elem in lowres_r2_GRE_SHIM0)\n",
        "      if not lowres_r2_shim_match:\n",
        "        print('********** Shim values check failed by',runlist[runs], ' **********')\n",
        "        shutil.rmtree(runlist[runs])  \n",
        "\n",
        "   \n",
        "print('********** Shim values check completed for all subjects **********')\n",
        "print('********** We can proceed **********')  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Coregistrations and data extraction"
      ],
      "metadata": {
        "id": "mb3LB3_JjZRf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSiCc2cJ4C-1"
      },
      "outputs": [],
      "source": [
        "# Here, we extract the signal within the spinal cord for each shim condition, using the following pipeline\n",
        "# Utilising the Spinal Cort Toolbox\n",
        "\n",
        "# The spinal cord is segmented from the T1w scan\n",
        "# The MGRE scans for all shim conditions are coregistered to the T1w scan\n",
        "# Then the warp field for T1w-->MGRE is applied to the spinal cord segmentation\n",
        "# Warping it to the space (and resolution) of the MGRE scan\n",
        "# As a result, we have a high quality segmentation, but coregistered and downsampled to the space of the MGRE scans\n",
        "t = time.time()\n",
        "Subjectdirs=sorted(glob.glob('/content/Subjects/'+'/*')) #Let's see how many subjects we have (for the pruposes of this demo, 1)\n",
        "\n",
        "# Note: This is a very MATLAB-inspired way of vectorisation\n",
        "for subject in range(len(Subjectdirs)): # First, we loop over every subject\n",
        "\n",
        "  runlist = sorted(glob.glob(Subjectdirs[subject]+ '/nifti/*')) #We determine if more than one set of acquisitions (runs) was carried out for this subject\n",
        "  for runs in range(len(runlist)) : #And we loop over them\n",
        "    if fnmatch.fnmatch(runlist[runs], '*Lowres_run1*') : #Identifying the first low-resolution MGRE run\n",
        "    # Here, we create a new directory to do all this processing in (to keep the converted nifti directory clean)\n",
        "    # If this directory already exists within this colab, we delete it, to start with a clean slate\n",
        "      if os.path.isdir(runlist[runs]+'/processing'): \n",
        "        shutil.rmtree(runlist[runs]+'/processing')  \n",
        "      os.makedirs(runlist[runs]+'/processing')\n",
        "      # We change into the directory of this set of acquisitons. If we run our Spinal Cord Toolbox commands from within this\n",
        "      # Directory, then the commands are simpler, because there is less need to specify absolute paths in every step\n",
        "      os.chdir(runlist[runs]+'/processing')\n",
        "\n",
        "      # We need to identify the T1w file, which will serve as our scan on which we segment the spinal cor\n",
        "      # We might encounter previously exsisitng spinal cord segmentations, coregistrations, etc involving the T1w scan\n",
        "      # These are removed to make sure we get a clean slate\n",
        "      T1wfile_lowres_run1 = sorted(glob.glob(runlist[runs]+'/*T1w*.nii*'))\n",
        "      for T1files in range(len(T1wfile_lowres_run1)):\n",
        "        if fnmatch.fnmatch(T1wfile_lowres_run1[T1files], '*reg*') or fnmatch.fnmatch(T1wfile_lowres_run1[T1files], '*spinal*') or fnmatch.fnmatch(T1wfile_lowres_run1[T1files], '*mask*') : \n",
        "          os.remove(T1wfile_lowres_run1[T1files])\n",
        "      # After we have cleared up all the potentially pre-exsisting segmentation files, etc, we check if there is more than one file left\n",
        "      # And exit with error if there is!  \n",
        "      if not len(T1wfile_lowres_run1) == 1 :\n",
        "        print(\"********** More than one T1w file left after removing segmentation/registration files **********\")\n",
        "        print(\"********** Something is not right! **********\")\n",
        "        print(\"********** Please check your data! **********\")\n",
        "        print(\"********** Exiting **********\")\n",
        "        break\n",
        "      else:\n",
        "        print('********** Correct number of T1w files found in',runlist[runs],', proceeding! **********')\n",
        "      #Here, we define the filenames for the spinal cord segmenation and the mask that will be used\n",
        "      segfilename='spinal_seg.nii' \n",
        "      maskfilename='mask_cord.nii' \n",
        "      # Once we have these names, we can proceed with segmentation and masking\n",
        "      run_subprocess(f\"sct_deepseg_sc -i {(T1wfile_lowres_run1[T1files])} -c t1 -qc qc -o {segfilename}\")\n",
        "      # Mask creation using the spinal cord coolbox. This mask is useful for speeding up coregistration\n",
        "      run_subprocess(f\"sct_create_mask -i {T1wfile_lowres_run1[T1files]} -p centerline,{segfilename} -size 45mm -f cylinder -o {maskfilename}\")\n",
        "      print('********** Segmentation and massking of the spinal cord from the T1w scan complete! **********')\n",
        "\n",
        "      # Next, we proceed to coregister the MGRE scans to the T1w scan, applying the inverse warp to the\n",
        "      # segmentation, and finally extract the intensity values \n",
        "\n",
        "      # Processing the NOSHIM condition\n",
        "      NOSHIMfile=sorted(glob.glob(runlist[runs]+'/*NOSHIM*.nii*'))      \n",
        "      if not len(NOSHIMfile)==1: #Quick sanity check to make sure we don't have more than one NOSHIM nifti file\n",
        "        # If we do, we have probably run this cell again (as one of the steps is splitting the MGRE scan)\n",
        "        # We can use the fact that splitting adds T0000 to T0005 to the filename, and sorted puts those last\n",
        "        # However, we still need to flag this issue to the user\n",
        "        # It is left up to the user to clean their data if the file is not the correct one\n",
        "        print('********** More than one NOSHIM scan found! **********')\n",
        "        print('********** Using ',NOSHIMfile[0],' as the no shim condition scan, please make sure this is the correct one **********')\n",
        "\n",
        "      # Then we need to define some filenames  \n",
        "      meanname_NOSHIM='noshim_mean.nii.gz' \n",
        "      csvfile_NOSHIM='noshim_data.csv'\n",
        "      outfile_NOSHIM='spinal_seg_reg_noshim.nii.gz'\n",
        "      # We create the mean across echoes of the MGRE scan\n",
        "      # This will increase the SNR and improve the outcome of the coregistration\n",
        "      run_subprocess(f\"sct_maths -i {NOSHIMfile[0]} -mean t -o {meanname_NOSHIM}\")\n",
        "      # Here we coregister the mean MGRE scan to the T1w\n",
        "      run_subprocess(f\"sct_register_multimodal -i {meanname_NOSHIM} -d {T1wfile_lowres_run1[T1files]} -dseg {segfilename} -m {maskfilename} -param step=1,type=im,metric=cc,algo=slicereg,poly=2,smooth=1 -qc qc\")\n",
        "      # We grab the warp field file for the inverse (T1w-->MGRE) operation\n",
        "      warpNOSHIM2T1w=sorted(glob.glob(runlist[runs]+'/processing/warp_Lowres*noshim*.nii*'))[0] \n",
        "      # We apply this warp filed to the segmentation    \n",
        "      run_subprocess(f\"sct_apply_transfo -i {segfilename} -d {meanname_NOSHIM} -w {warpNOSHIM2T1w} -x nn -o {outfile_NOSHIM}\")\n",
        "      # We split the MGRE scan into individual echoes\n",
        "      run_subprocess(f\"sct_image -i {NOSHIMfile[0]} -split t\")\n",
        "      noshim_splitnames=sorted(glob.glob(runlist[runs]+'/*NOSHIM*T*.nii*'))\n",
        "      # And finally, using the warped segmentation, we extract the signal value for each echo and slice\n",
        "      for noshim_splitfiles in range(len(noshim_splitnames)):\n",
        "        run_subprocess(f\"sct_extract_metric -i {noshim_splitnames[noshim_splitfiles]} -f {outfile_NOSHIM} -method wa -o {csvfile_NOSHIM} -perslice 1 -append 1\")\n",
        "      \n",
        "      # Processing the Static Z-SHIM condition\n",
        "      # Comments omitted for brevity. Same pipeline as NOSHIM\n",
        "      STATICZSHIMfile=sorted(glob.glob(runlist[runs]+'/*staticzSHIM*.nii*'))\n",
        "      if not len(STATICZSHIMfile)==1: \n",
        "        print('********** More than one static Z-shim scan found! **********')\n",
        "        print('********** Using ',STATICZSHIMfile[0],' as the static z-shimming scan, please make sure this is the correct one **********')\n",
        "      meanname_STATICZSHIM='staticzshim_mean.nii.gz'\n",
        "      csvfile_STATICZSHIM='staticzshim_data.csv'\n",
        "      run_subprocess(f\"sct_maths -i {STATICZSHIMfile[0]} -mean t -o {meanname_STATICZSHIM}\")\n",
        "      run_subprocess(f\"sct_register_multimodal -i {meanname_STATICZSHIM} -d {T1wfile_lowres_run1[T1files]} -dseg {segfilename} -m {maskfilename} -param step=1,type=im,metric=cc,algo=slicereg,poly=2,smooth=1 -qc qc\")\n",
        "      warpSTATICZSHIM2T1w=glob.glob(runlist[runs]+'/processing/warp_Lowres*staticzshim*.nii*')[0]\n",
        "      outfile_STATICZSHIM='spinal_seg_reg_staticzshim.nii.gz' \n",
        "      run_subprocess(f\"sct_apply_transfo -i {segfilename} -d {meanname_STATICZSHIM} -w {warpSTATICZSHIM2T1w} -x nn -o {outfile_STATICZSHIM}\")\n",
        "      run_subprocess(f\"sct_image -i {STATICZSHIMfile[0]} -split t\")\n",
        "      staticzshim_splitnames=sorted(glob.glob(runlist[runs]+'/*staticzSHIM*T*.nii*'))\n",
        "      for staticzshim_splitfiles in range(len(staticzshim_splitnames)):\n",
        "        run_subprocess(f\"sct_extract_metric -i {staticzshim_splitnames[staticzshim_splitfiles]} -f {outfile_STATICZSHIM} -method wa -o {csvfile_STATICZSHIM} -perslice 1 -append 1\")\n",
        "\n",
        "      # Processing the STATIC XYZ-SHIM condition\n",
        "      # Comments omitted for brevity. Same pipeline as NOSHIM\n",
        "      STATICSHIMfile=sorted(glob.glob(runlist[runs]+'/*staticSHIM*.nii*'))\n",
        "      if not len(STATICSHIMfile)==1: \n",
        "        print('********** More than one static xyz-shim scan found! **********')\n",
        "        print('********** Using ',STATICSHIMfile[0],' as the static xyz-shimming scan, please make sure this is the correct one **********')\n",
        "      meanname_STATICSHIM='staticshim_mean.nii.gz'\n",
        "      csvfile_STATICSHIM='staticshim_data.csv'\n",
        "      run_subprocess(f\"sct_maths -i {STATICSHIMfile[0]} -mean t -o {meanname_STATICSHIM}\")\n",
        "      run_subprocess(f\"sct_register_multimodal -i {meanname_STATICSHIM} -d {T1wfile_lowres_run1[T1files]} -dseg {segfilename} -m {maskfilename} -param step=1,type=im,metric=cc,algo=slicereg,poly=2,smooth=1 -qc qc\")\n",
        "      warpSTATICSHIM2T1w=glob.glob(runlist[runs]+'/processing/warp_Lowres*staticshim*.nii*')[0]\n",
        "      outfile_STATICSHIM='spinal_seg_reg_staticshim.nii.gz' \n",
        "      run_subprocess(f\"sct_apply_transfo -i {segfilename} -d {meanname_STATICSHIM} -w {warpSTATICSHIM2T1w} -x nn -o {outfile_STATICSHIM}\")\n",
        "      run_subprocess(f\"sct_image -i {STATICSHIMfile[0]} -split t\")\n",
        "      staticshim_splitnames=sorted(glob.glob(runlist[runs]+'/*staticSHIM*T*.nii*'))\n",
        "      for staticshim_splitfiles in range(len(staticshim_splitnames)):\n",
        "        run_subprocess(f\"sct_extract_metric -i {staticshim_splitnames[staticshim_splitfiles]} -f {outfile_STATICSHIM} -method wa -o {csvfile_STATICSHIM} -perslice 1 -append 1\")\n",
        "    \n",
        "      # Processing the Realtime Z-SHIM condition\n",
        "      # Comments omitted for brevity. Same pipeline as NOSHIM\n",
        "      RTZSHIMfile=sorted(glob.glob(runlist[runs]+'/*rtzSHIM*.nii*'))\n",
        "      if not len(RTZSHIMfile)==1: \n",
        "        print('********** More than one Realtime Z-shim scan found! **********')\n",
        "        print('********** Using ',RTZSHIMfile[0],' as the realtime z-shimming scan, please make sure this is the correct one **********')\n",
        "      meanname_RTZSHIM='rtzshim_mean.nii.gz'\n",
        "      csvfile_RTZSHIM='rtzshim_data.csv'\n",
        "      run_subprocess(f\"sct_maths -i {RTZSHIMfile[0]} -mean t -o {meanname_RTZSHIM}\")\n",
        "      run_subprocess(f\"sct_register_multimodal -i {meanname_RTZSHIM} -d {T1wfile_lowres_run1[T1files]} -dseg {segfilename} -m {maskfilename} -param step=1,type=im,metric=cc,algo=slicereg,poly=2,smooth=1 -qc qc\")\n",
        "      warpRTZSHIM2T1w=glob.glob(runlist[runs]+'/processing/warp_Lowres*rtzshim*.nii*')[0]\n",
        "      outfile_RTZSHIM='spinal_seg_reg_rtzshim.nii.gz' \n",
        "      run_subprocess(f\"sct_apply_transfo -i {segfilename} -d {meanname_RTZSHIM} -w {warpRTZSHIM2T1w} -x nn -o {outfile_RTZSHIM}\")\n",
        "      run_subprocess(f\"sct_image -i {RTZSHIMfile[0]} -split t\")\n",
        "      rtzshim_splitnames=sorted(glob.glob(runlist[runs]+'/*rtzSHIM*T*.nii*'))\n",
        "      for rtzshim_splitfiles in range(len(rtzshim_splitnames)):\n",
        "        run_subprocess(f\"sct_extract_metric -i {rtzshim_splitnames[rtzshim_splitfiles]} -f {outfile_RTZSHIM} -method wa -o {csvfile_RTZSHIM} -perslice 1 -append 1\")\n",
        "      \n",
        "      # Processing the Realtime XYZ-SHIM condition\n",
        "      # Comments omitted for brevity. Same pipeline as NOSHIM\n",
        "      RTSHIMfile=sorted(glob.glob(runlist[runs]+'/*rtSHIM*.nii*'))\n",
        "      if not len(RTSHIMfile)==1: \n",
        "        print('********** More than one Realtime XYZ-shim scan found! **********')\n",
        "        print('********** Using ',RTSHIMfile[0],' as the realtime xyz-shimming scan, please make sure this is the correct one **********')\n",
        "   \n",
        "      meanname_RTSHIM='rtshim_mean.nii.gz'\n",
        "      csvfile_RTSHIM='rtshim_data.csv'\n",
        "      run_subprocess(f\"sct_maths -i {RTSHIMfile[0]} -mean t -o {meanname_RTSHIM}\")\n",
        "      run_subprocess(f\"sct_register_multimodal -i {meanname_RTSHIM} -d {T1wfile_lowres_run1[T1files]} -dseg {segfilename} -m {maskfilename} -param step=1,type=im,metric=cc,algo=slicereg,poly=2,smooth=1 -qc qc\")\n",
        "      warpRTSHIM2T1w=glob.glob(runlist[runs]+'/processing/warp_Lowres*rtshim*.nii*')[0]\n",
        "      outfile_RTSHIM='spinal_seg_reg_rtshim.nii.gz' \n",
        "      run_subprocess(f\"sct_apply_transfo -i {segfilename} -d {meanname_RTSHIM} -w {warpRTSHIM2T1w} -x nn -o {outfile_RTSHIM}\")\n",
        "      run_subprocess(f\"sct_image -i {RTSHIMfile[0]} -split t\")\n",
        "      rtshim_splitnames=sorted(glob.glob(runlist[runs]+'/*rtSHIM*T*.nii*'))\n",
        "      for rtshim_splitfiles in range(len(rtshim_splitnames)):\n",
        "        run_subprocess(f\"sct_extract_metric -i {rtshim_splitnames[rtshim_splitfiles]} -f {outfile_RTSHIM} -method wa -o {csvfile_RTSHIM} -perslice 1 -append 1\")\n",
        "     \n",
        "      print('********** All shim conditions processed for ',runlist[runs], ' **********')\n",
        "\n",
        "\n",
        "# We also define a helper function here to extract the mean and standard deviation across slices from the data \n",
        "def data_extractor(csv_filename):\n",
        "  # Load the CSV file into a Pandas DataFrame\n",
        "  dataframe_STD=pd.read_csv(csv_filename, sep=\",\")\n",
        "  # Convert all the strings (123.4242, etc) of the WA column (that contains the signal intensity) into actual numerical values\n",
        "  dataframe_STD['WA()'] = pd.to_numeric(dataframe_STD['WA()'], errors='coerce')\n",
        "  # Determine the number of slices, which is given by the maximum value of the \"Slice (I-->S) of the CSV, plus 1, because the index starts at 0\"\n",
        "  nSlices=int(np.max(dataframe_STD.iloc[:,3])+1)\n",
        "  # Then the number of echoes is simply the size of the original data deivided by the number of slices\n",
        "  nEchoes=int(np.size(dataframe_STD['WA()'])/nSlices)\n",
        "  # Convert this column of the Pandas Dataframe into a matrix for easier handling\n",
        "  WA_matrix=dataframe_STD['WA()'].to_numpy()\n",
        "  # And reshape it so it looks like a echoes-by-slices matrix\n",
        "  WA_matrix_reshaped=WA_matrix.reshape(nEchoes,nSlices)\n",
        "  # Calculate the standard deviation across all slices for each echo\n",
        "  WA_std_across_slices=np.nanstd(WA_matrix_reshaped,axis=1,ddof=1) ## To make it equivalent with MATLAB STD (dividing by N-1, not N)\n",
        "  WA_mean_across_slices=np.nanmean(WA_matrix_reshaped,axis=1) ## To make it equivalent with MATLAB STD (dividing by N-1, not N)\n",
        "  return [WA_mean_across_slices,WA_std_across_slices,WA_matrix_reshaped] \n",
        "\n",
        "\n",
        "elapsed = time.time() -t\n",
        "print('********** Data extraction completed for all subjects! **********')\n",
        "print('********** And it only took',elapsed, 'seconds **********')\n",
        "#done"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data visualisation"
      ],
      "metadata": {
        "id": "a8yDejrJdo_z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XF9jkj16h1V-"
      },
      "outputs": [],
      "source": [
        "# Data visualisation\n",
        "\n",
        "Subjectdirs=sorted(glob.glob('/content/Subjects/'+'/*')) #Let's see how many subjects we have (for the pruposes of this demo, 1)\n",
        "\n",
        "# Note: This is a very MATLAB-inspired way of vectorisation\n",
        "for subject in range(len(Subjectdirs)): # First, we loop over every subject\n",
        "\n",
        "  runlist = sorted(glob.glob(Subjectdirs[subject]+ '/nifti/*')) #We determine if more than one set of acquisitions (runs) was carried out for this subject\n",
        "  for runs in range(len(runlist)) : #And we loop over them\n",
        "    if fnmatch.fnmatch(runlist[runs], '*Lowres_run1*') : #Identifying the first low-resolution MGRE run\n",
        "\n",
        "      #Now, we grab the CSV files that correspond to the shim conditions and extract the mean and std across slices from them\n",
        "      # Noshim condition     \n",
        "      Lowres_run1_noshim_CSV=glob.glob((runlist[runs]+'/processing/*noshim*.csv'))[0]\n",
        "      [noshim_mean_across_slices_r1,noshim_STD_slices_r1,WA_matrix_noshim_r1]=data_extractor(Lowres_run1_noshim_CSV)\n",
        "\n",
        "      # Static z-shim condition      \n",
        "      Lowres_run1_staticzshim_CSV=glob.glob((runlist[runs]+'/processing/*staticzshim*.csv'))[0]\n",
        "      [staticzshim_mean_across_slices_r1,staticzshim_STD_slices_r1,WA_matrix_staticzshim_r1]=data_extractor(Lowres_run1_staticzshim_CSV)\n",
        "\n",
        "      # Static xyz-shim condition      \n",
        "      Lowres_run1_staticshim_CSV=glob.glob((runlist[runs]+'/processing/*staticshim*.csv'))[0]\n",
        "      [staticshim_mean_across_slices_r1,staticshim_STD_slices_r1,WA_matrix_staticshim_r1]=data_extractor(Lowres_run1_staticshim_CSV)\n",
        "\n",
        "      # Realtime z-shim condition      \n",
        "      Lowres_run1_rtzshim_CSV=glob.glob((runlist[runs]+'/processing/*rtzshim*.csv'))[0]\n",
        "      [rtzshim_mean_across_slices_r1,rtzshim_STD_slices_r1,WA_matrix_rtzshim_r1]=data_extractor(Lowres_run1_rtzshim_CSV)\n",
        "\n",
        "      # Realtime xyz-shim condition      \n",
        "      Lowres_run1_rtshim_CSV=glob.glob((runlist[runs]+'/processing/*rtshim*.csv'))[0]\n",
        "      [rtshim_mean_across_slices_r1,rtshim_STD_slices_r1,WA_matrix_rtshim_r1]=data_extractor(Lowres_run1_rtshim_CSV)\n",
        "\n",
        "      #Lets populate the two matrices we will use to plot data, and recreate the bar charts in the poster \n",
        "      Plotmatrix_lowres_STD=np.array([noshim_STD_slices_r1,staticzshim_STD_slices_r1,staticshim_STD_slices_r1,rtzshim_STD_slices_r1,rtshim_STD_slices_r1])\n",
        "      Plotmatrix_lowres_mean=np.array([noshim_mean_across_slices_r1,staticzshim_mean_across_slices_r1,staticshim_mean_across_slices_r1,rtzshim_mean_across_slices_r1,rtshim_mean_across_slices_r1])\n",
        "      \n",
        "      # For the purposes of generalisation, we define an error matrix\n",
        "      Plotmatrix_lowres_STD_errorbar=np.zeros_like(Plotmatrix_lowres_STD)\n",
        "      Plotmatrix_lowres_mean_errorbar=np.zeros_like(Plotmatrix_lowres_mean)  \n",
        "   \n",
        "      # Plotting std across slices and mean across slices using Plotly\n",
        "      # TThese are interactive versions of the bar graphs in our poster\n",
        "      TEs = ['2.3 ms', '4.5 ms', '6.7 ms', '8.9 ms', '11.1 ms', '13.3 ms']\n",
        "      # STD\n",
        "      fig = go.Figure()      \n",
        "      fig.add_trace(go.Bar(x=TEs,y=Plotmatrix_lowres_STD[0],error_y=dict(type='data', array=Plotmatrix_lowres_STD_errorbar[0]), name='NO Shim',marker_color='black'))\n",
        "      fig.add_trace(go.Bar(x=TEs,y=Plotmatrix_lowres_STD[1],error_y=dict(type='data', array=Plotmatrix_lowres_STD_errorbar[1]), name='Static Z-shim',marker_color='blue'))\n",
        "      fig.add_trace(go.Bar(x=TEs,y=Plotmatrix_lowres_STD[2],error_y=dict(type='data', array=Plotmatrix_lowres_STD_errorbar[2]), name='Static XYZ-shim',marker_color='green'))\n",
        "      fig.add_trace(go.Bar(x=TEs,y=Plotmatrix_lowres_STD[3],error_y=dict(type='data', array=Plotmatrix_lowres_STD_errorbar[3]), name='Realtime Z-shim',marker_color='orange'))\n",
        "      fig.add_trace(go.Bar(x=TEs,y=Plotmatrix_lowres_STD[4],error_y=dict(type='data', array=Plotmatrix_lowres_STD_errorbar[4]), name='Realtime XYZ-shim',marker_color='red'))\n",
        "      fig.update_xaxes(showgrid=False, showline=True, linewidth=1, linecolor='black', mirror=True)\n",
        "      fig.update_yaxes(showgrid=False, showline=True, linewidth=1, linecolor='black', mirror=True)   \n",
        "      fig.update_layout(title={'y':0.9,'x':0.5,'xanchor': 'center','yanchor': 'top'},plot_bgcolor=\"white\")\n",
        "      fig.update_layout(barmode='group',xaxis_title=\"Echo Time\",yaxis_title=\"STD across slices [au]\" ,title_text='Standard deviation (across slices) of the signal within the SC')\n",
        "      fig.show()\n",
        "      # Mean\n",
        "      fig = go.Figure()      \n",
        "      fig.add_trace(go.Bar(x=TEs,y=Plotmatrix_lowres_mean[0],name='NO Shim',marker_color='black'))\n",
        "      fig.add_trace(go.Bar(x=TEs,y=Plotmatrix_lowres_mean[1],name='Static Z-shim',marker_color='blue'))\n",
        "      fig.add_trace(go.Bar(x=TEs,y=Plotmatrix_lowres_mean[2],name='Static XYZ-shim',marker_color='green'))\n",
        "      fig.add_trace(go.Bar(x=TEs,y=Plotmatrix_lowres_mean[3],name='Realtime Z-shim',marker_color='orange'))\n",
        "      fig.add_trace(go.Bar(x=TEs,y=Plotmatrix_lowres_mean[4],name='Realtime XYZ-shim',marker_color='red'))\n",
        "      fig.update_xaxes(showgrid=False, showline=True, linewidth=1, linecolor='black', mirror=True)\n",
        "      fig.update_yaxes(showgrid=False, showline=True, linewidth=1, linecolor='black', mirror=True)   \n",
        "      fig.update_layout(title={'y':0.9,'x':0.5,'xanchor': 'center','yanchor': 'top'},plot_bgcolor=\"white\")\n",
        "      fig.update_layout(barmode='group',xaxis_title=\"Echo Time\",yaxis_title=\"Mean across slices [au]\" ,title_text='Mean signal across slices within the SC')\n",
        "      fig.show()    \n",
        "\n",
        "      # Using Seaborn, we are plotting a few violin plots\n",
        "      # Because we can not use Seaborn to plot us groups of five, we have a few options\n",
        "      # We use two groups of 3 (noshim, static z-shim, static xyz-shim as group 1\n",
        "      # and noshim, realtime z-shim, realtime xyz-shim as group 2)\n",
        "      # And then we have pairwise, two-sided violin plots comparing noshim with shim conditions\n",
        "\n",
        "      # Group A: No/staticz/static\n",
        "      A = np.concatenate((WA_matrix_noshim_r1[...,None], WA_matrix_staticzshim_r1[...,None]), axis=2)\n",
        "      NOShim_Static = np.concatenate((A, WA_matrix_staticshim_r1[...,None]), axis=2)\n",
        "      dim1_Static, dim2_Static, dim3_Static = np.meshgrid(np.arange(NOShim_Static.shape[0]), np.arange(NOShim_Static.shape[1]), np.arange(NOShim_Static.shape[2]), indexing='ij')\n",
        "      plt.figure(figsize=(16, 12))\n",
        "      ax = sns.violinplot(x=dim1_Static.ravel(), y=NOShim_Static.ravel(), hue=dim3_Static.ravel(),bw=1,palette=['k','b','g'])\n",
        "      #ax = sns.swarmplot(color = 'black',alpha = 0.3,x=dim1_Static.ravel(), y=NOShim_RT.ravel(), hue=dim3_Static.ravel(),dodge=True, ax=ax)\n",
        "      ax.set_xticklabels(['2.3 ms', '4.5 ms', '6.7 ms','8.9 ms','11.1 ms','13.3 ms'])\n",
        "      ax.set_xlabel(\"Echo time\")\n",
        "      ax.legend(handles=ax.legend_.legendHandles, labels=['NO shim', 'Static Z-shim','Static XYZ-shim'])\n",
        "      plt.title(\"Noshim, Static Z-shim and Static XYZ-shim violin plot\")\n",
        "      plt.setp(ax.collections, alpha=.7)\n",
        "      plt.show()\n",
        "\n",
        "      # Group B: No/staticz/static\n",
        "      B = np.concatenate((WA_matrix_noshim_r1[...,None], WA_matrix_rtzshim_r1[...,None]), axis=2)\n",
        "      NOShim_RT = np.concatenate((B, WA_matrix_rtshim_r1[...,None]), axis=2)\n",
        "      dim1_rt, dim2_rt, dim3_rt = np.meshgrid(np.arange(NOShim_RT.shape[0]), np.arange(NOShim_RT.shape[1]), np.arange(NOShim_RT.shape[2]), indexing='ij')\n",
        "      plt.figure(figsize=(16, 12))\n",
        "      ax = sns.violinplot(x=dim1_rt.ravel(), y=NOShim_RT.ravel(), hue=dim3_rt.ravel(), palette=['k','orange','r'],bw=1)\n",
        "      #ax = sns.swarmplot(color = 'black',alpha = 0.3,x=dim1_Static.ravel(), y=B.ravel(), hue=dim3_Static.ravel(),dodge=True, ax=ax)\n",
        "      ax.set_xticklabels(['2.3 ms', '4.5 ms', '6.7 ms','8.9 ms','11.1 ms','13.3 ms'])\n",
        "      ax.set_xlabel(\"Echo time\")\n",
        "      ax.legend(handles=ax.legend_.legendHandles, labels=['NO shim', 'Realtime Z-shim','Static XYZ-shim'])\n",
        "      plt.title(\"Noshim, Realtime Z-shim and Realtime XYZ-shim violin plot\")\n",
        "      plt.setp(ax.collections, alpha=.7)\n",
        "      plt.show()\n",
        "\n",
        "      #Pairwise plot 1: Noshim vs Static Z-shim\n",
        "      C = np.concatenate((WA_matrix_noshim_r1[...,None], WA_matrix_staticzshim_r1[...,None]), axis=2)\n",
        "      dim1, dim2, dim3 = np.meshgrid(np.arange(C.shape[0]), np.arange(C.shape[1]), np.arange(C.shape[2]), indexing='ij')  \n",
        "      plt.figure(figsize=(12, 10))\n",
        "      ax = sns.violinplot(x=dim1.ravel(), y=C.ravel(), hue=dim3.ravel(), palette=['k','b'], bw=1, split=True, inner=\"stick\", linewidth=0.3)\n",
        "      ax.set_xticklabels(['2.3 ms', '4.5 ms', '6.7 ms','8.9 ms','11.1 ms','13.3 ms'])\n",
        "      ax.set_xlabel(\"Echo time\")\n",
        "      ax.legend(handles=ax.legend_.legendHandles, labels=['NO shim','Static Z-shim'])\n",
        "      plt.title(\"Pairwise vilon plot for Noshim and Static Z-shimming condition\")\n",
        "      plt.setp(ax.collections, alpha=.7)\n",
        "      plt.show()\n",
        "      #Pairwise plot 2: Noshim vs Static XYZ-shim\n",
        "      C = np.concatenate((WA_matrix_noshim_r1[...,None], WA_matrix_staticshim_r1[...,None]), axis=2)\n",
        "      dim1, dim2, dim3 = np.meshgrid(np.arange(C.shape[0]), np.arange(C.shape[1]), np.arange(C.shape[2]), indexing='ij')  \n",
        "      plt.figure(figsize=(12, 10))\n",
        "      ax = sns.violinplot(x=dim1.ravel(), y=C.ravel(), hue=dim3.ravel(), palette=['k','g'], bw=1, split=True, inner=\"stick\", linewidth=0.3)\n",
        "      ax.set_xticklabels(['2.3 ms', '4.5 ms', '6.7 ms','8.9 ms','11.1 ms','13.3 ms'])\n",
        "      ax.set_xlabel(\"Echo time\")\n",
        "      ax.legend(handles=ax.legend_.legendHandles, labels=['NO shim','Static XYZ-shim'])\n",
        "      plt.title(\"Pairwise vilon plot for Noshim and Static XYZ-shimming condition\")\n",
        "      plt.setp(ax.collections, alpha=.7)\n",
        "      plt.show()\n",
        "      #Pairwise plot 3: Noshim vs Realtime Z-shim\n",
        "      C = np.concatenate((WA_matrix_noshim_r1[...,None], WA_matrix_rtzshim_r1[...,None]), axis=2)\n",
        "      dim1, dim2, dim3 = np.meshgrid(np.arange(C.shape[0]), np.arange(C.shape[1]), np.arange(C.shape[2]), indexing='ij')  \n",
        "      plt.figure(figsize=(12, 10))\n",
        "      ax = sns.violinplot(x=dim1.ravel(), y=C.ravel(), hue=dim3.ravel(), palette=['k','orange'], bw=1, split=True, inner=\"stick\", linewidth=0.3)\n",
        "      ax.set_xticklabels(['2.3 ms', '4.5 ms', '6.7 ms','8.9 ms','11.1 ms','13.3 ms'])\n",
        "      ax.set_xlabel(\"Echo time\")\n",
        "      ax.legend(handles=ax.legend_.legendHandles, labels=['NO shim','Realtime Z-shim'])\n",
        "      plt.title(\"Pairwise vilon plot for Noshim and Reltime Z-shimming condition\")\n",
        "      plt.setp(ax.collections, alpha=.7)\n",
        "      plt.show()\n",
        "      #Pairwise plot 4: Noshim vs Realtime XYZ-shim\n",
        "      C = np.concatenate((WA_matrix_noshim_r1[...,None], WA_matrix_rtshim_r1[...,None]), axis=2)\n",
        "      dim1, dim2, dim3 = np.meshgrid(np.arange(C.shape[0]), np.arange(C.shape[1]), np.arange(C.shape[2]), indexing='ij')  \n",
        "      plt.figure(figsize=(12, 10))\n",
        "      ax = sns.violinplot(x=dim1.ravel(), y=C.ravel(), hue=dim3.ravel(), palette=['k','red'], bw=1, split=True, inner=\"stick\", linewidth=0.3)\n",
        "      ax.set_xticklabels(['2.3 ms', '4.5 ms', '6.7 ms','8.9 ms','11.1 ms','13.3 ms'])\n",
        "      ax.set_xlabel(\"Echo time\")\n",
        "      ax.legend(handles=ax.legend_.legendHandles, labels=['NO shim','Realtime XYZ-shim'])\n",
        "      plt.title(\"Pairwise vilon plot for Noshim and Reltime XYZ-shimming condition\")\n",
        "      plt.setp(ax.collections, alpha=.7)\n",
        "      plt.show()\n",
        "\n",
        "#End of Loop\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Realtime_dynanmic_xyz_shimming_in_the_cervical_spinal_cord.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOAu51vKvR0p1OxMmTW14Ie",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}